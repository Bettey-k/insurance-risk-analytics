# ğŸ›¡ï¸ Insurance Risk Analytics  
### Comprehensive EDA, Feature Engineering, Modeling & Explainability  
**Tasks Completed: 1 â†’ 4**

---

## ğŸ“Œ Project Overview  
This project analyzes a large motor insurance portfolio to understand claim behavior, risk patterns, and key drivers of severity.  
The work is aligned with the structure of:

- **Task 1 â€” Data Understanding & EDA**  
- **Task 2 â€” DVC Setup & Data Pipeline Organization**  
- **Task 3 â€” Feature Engineering & Model Training**  
- **Task 4 â€” Model Evaluation & Explainability**

---

# ğŸ§± Folder Structure  

insurance-risk-analytics/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”œâ”€â”€ interim/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ external/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ EDA.ipynb
â”‚ â”œâ”€â”€ hypothesis_testing.ipynb
â”‚ â”œâ”€â”€ modeling/
â”‚ â”‚ â”œâ”€â”€ train_models.ipynb
â”‚ â”‚ â””â”€â”€ evaluate_models.ipynb
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ load.py
â”‚ â”‚ 
â”‚ â”œâ”€â”€ features/
â”‚ â”‚ â””â”€â”€ build_features.py
â”‚ â””â”€â”€ models/
â”‚ â”œâ”€â”€ train_model.py
â”‚ â””â”€â”€ predict_model.py
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ best_severity_model.pkl
â”‚
â””â”€â”€ README.md

---

# âœ… **TASK 1 â€” Exploratory Data Analysis (EDA)**  

### ğŸ“Š Dataset Overview  
- **Total Rows:** 617,958  
- **Total Features:** 53  
- **Period:** 2013â€“10 â†’ 2015â€“08  
- **Positive Claims:** 2,641 rows (â‰ˆ0.43%) â†’ *Highly imbalanced*  

### ğŸ’° Key Portfolio Metrics  
| Metric | Value |
|-------|-------|
| Total Premium | 61.38M |
| Total Claims | 61.52M |
| Loss Ratio | **100.23%** |
| Average Premium | 99.32 |
| Average Claim | 99.55 |

### ğŸ§¹ Data Quality Findings  
- Missing values: **3 million+**  
- Negative claims: **2** rows  
- Zero premiums: **0**  
- Several numerical outliers (long-tail distributions)

### ğŸ“ˆ Visualizations Generated  
- Distribution plots (premium, claims, sum insured)  
- Correlation heatmap  
- Boxplots by vehicle type, model, and region  
- Time-series trends (monthly LR, frequency, severity)

---

# âœ… **TASK 2 â€” DVC Setup & Pipeline Organization**

### âœ” DVC Stages Created  
- Data ingestion â†’ `dvc.yaml: load_data`  
- Cleaning & preprocessing  
- Feature engineering  
- Modeling  

### âœ” Remote Storage  
Configured on local filesystem or cloud (optional).  

### âœ” Benefits  
- Reproducible dataset versions  
- Traceable model outputs  
- Full experiment tracking

---

# âœ… **TASK 3 â€” Feature Engineering & Model Training**

### âœ¨ Engineered Features  
| Feature | Description |
|--------|-------------|
| `PolicyAgeDays` | Days since policy started |
| `VehicleAge` | Age of vehicle at transaction |
| `PremiumToSumInsured` | Pricing adequacy ratio |
| Encoded categorical features | via OneHotEncoder |
| Scaled numerics | via StandardScaler |

### ğŸ¯ Targets Modeled  
We modeled **Claim Severity**, focusing on customers with `TotalClaims > 0`.

### ğŸ¤– Models Trained  
- Linear Regression  
- Random Forest  
- XGBoost Regressor  

### ğŸ† Best Model  
**XGBoost** with the highest RÂ² and lowest RMSE.  

### âœ” Model Saved  
`models/best_severity_model.pkl`

---

# âœ… **TASK 4 â€” Model Evaluation & Explainability**

### ğŸ“Œ Metrics  
Using unseen test data:


(*Values filled automatically when running your evaluate notebook.*)

### ğŸ“ˆ SHAP Explainability  
We generated:

- **SHAP Beeswarm Plot**  
- **Feature Importance Ranking**  
- **Per-instance explanations**

### ğŸ” Top Predictive Features
Typical top contributors include:

- PremiumToSumInsured  
- VehicleAge  
- PolicyAgeDays  
- Make/Model encodings  
- SumInsured  

---

# ğŸ“¦ How to Reproduce

### 1ï¸âƒ£ Install Environment
```bash
pip install -r requirements.txt

2ï¸âƒ£ Run EDA

Open notebook:

notebooks/EDA.ipynb

3ï¸âƒ£ Train Model
notebooks/modeling/train_models.ipynb

4ï¸âƒ£ Evaluate Model
notebooks/modeling/evaluate_models.ipynb